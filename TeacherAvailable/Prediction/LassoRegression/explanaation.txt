「ラッソ回帰」

(説明)
・過学習を防ぐことが目的で、内部計算で回帰係数を0にしたりして、不要な特徴量を
防ぐことができる。
・回帰係数の絶対値の和を損失関数を用いて回帰係数を小さくする
・リッジ回帰はバリアンスを低く調整することに焦点をおいて、バイアスが増えることを
妥協して、回帰係数を小さくすることが目的

(リッジ回帰とラッソ回帰の判断)
・特徴量選択が重要な場合や、モデルの解釈性を重視する場合はラッソ回帰が適してる。
　全ての特徴量に何らかの寄与を期待する場合はリッジ回帰の方が向いている

※ラッソ回帰も検証データを使う方が良い




